{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HatEval English Task B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put a description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and exploratin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to load the dataset in format CSV to a python DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201</td>\n",
       "      <td>Hurray, saving us $$$ in so many ways @potus @...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202</td>\n",
       "      <td>Why would young fighting age men be the vast m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203</td>\n",
       "      <td>@KamalaHarris Illegals Dump their Kids at the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204</td>\n",
       "      <td>NY Times: 'Nearly All White' States Pose 'an A...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>Orban in Brussels: European leaders are ignori...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>206</td>\n",
       "      <td>@KurtSchlichter LEGAL is. Not illegal. #BuildT...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>207</td>\n",
       "      <td>@RitaPanahi @826Maureen @RealCandaceO Antifa a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>208</td>\n",
       "      <td>Ex-Teacher Pleads Not guilty To Rape Charges h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>209</td>\n",
       "      <td>still places on our Bengali (Sylheti) class! i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>210</td>\n",
       "      <td>DFID Africa Regional Profile: July 2018 https:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>211</td>\n",
       "      <td>Watch: Benjamin Netanyahu backs Trump's decisi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>212</td>\n",
       "      <td>@RealDonaldTrump @HouseGOP Illegals are dumpin...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>213</td>\n",
       "      <td>While Costa Rica has received the most asylum ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>214</td>\n",
       "      <td>US immigrant policy to enter US has always bee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>215</td>\n",
       "      <td>Italy’s populist coalition poised to defy EU w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>216</td>\n",
       "      <td>Lithuania, Romania aided CIA torture, top Euro...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>217</td>\n",
       "      <td>Worldbank reports that in the next 30 years ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>218</td>\n",
       "      <td>Rich African Countries don't take in African M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>219</td>\n",
       "      <td>New research uncovers successes and failures o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>220</td>\n",
       "      <td>Immigration why us 2 Million EU Migrants allow...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>221</td>\n",
       "      <td>@NBCNews @MSNBC @jacobsoboroff @DatelineNBC Cl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>222</td>\n",
       "      <td>Hitler left a stain on Germany for the atrocit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>223</td>\n",
       "      <td>Over the past two weeks, 1,172 refugees arrive...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>224</td>\n",
       "      <td>Church leaders determine to ease #economic pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>225</td>\n",
       "      <td>And why should he now buckle to their demands ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>226</td>\n",
       "      <td>@WattersWorld @JesseBWatters @BillSpadea How a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>227</td>\n",
       "      <td>It is a cruel irony that sikhs often **look** ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>228</td>\n",
       "      <td>EU’s hailed migrant plan ‘˜a road to Hell’ Cze...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>229</td>\n",
       "      <td>Could you open up your home to refugees in nee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>230</td>\n",
       "      <td>MS-13 spreads to 22 states, fed by 300,000 ill...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8970</th>\n",
       "      <td>9171</td>\n",
       "      <td>nbs stfu hoe ik bout you</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>9172</td>\n",
       "      <td>PSA MMLD HATERS )) unfortunately for you, our ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>9173</td>\n",
       "      <td>@artbychristinem @AnnCoulter Perhaps Cory Book...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>9174</td>\n",
       "      <td>Yes Brooke! Give that bitch the hell she deser...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8974</th>\n",
       "      <td>9175</td>\n",
       "      <td>@GOPChairwoman @TWIGGY4065 I know. Booker and ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>9176</td>\n",
       "      <td>@howroute @legndofphoenix Lol you sound like t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>9177</td>\n",
       "      <td>@DogginTrump The whore bitch spoke! STFU Melan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>9178</td>\n",
       "      <td>@AnnCoulter But if the shoe was on the other f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>9179</td>\n",
       "      <td>Ladies want a task for your to do list today? ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>9180</td>\n",
       "      <td>The voices in your head arent YOU. Theyre your...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>9181</td>\n",
       "      <td>@onnyssaaa well stfu then BITCH you coming to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>9182</td>\n",
       "      <td>Once a stripper always a skank an a ( Y ) a ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>9183</td>\n",
       "      <td>One of the biggest reason I never wanted to co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>9184</td>\n",
       "      <td>All you niggas saying no grown man should be t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>9185</td>\n",
       "      <td>@DaddyDaddymac @_QueenofStaves @FLOTUS @FLOTUS...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>9186</td>\n",
       "      <td>Money can't buy you happiness but it can buy y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>9187</td>\n",
       "      <td>Real shit like stfu and eat my pussy since u c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>9188</td>\n",
       "      <td>' teaching women how to wear modest clothes an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>9189</td>\n",
       "      <td>@kimguilfoyle Does it bother you that Jrs kids...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>9190</td>\n",
       "      <td>@AnnCoulter Ann you are the funniest. I think ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>9191</td>\n",
       "      <td>@eyehatezod @PopeRichard I refuse to believe t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>9192</td>\n",
       "      <td>@CliffShep @MiaFarrow @realDonaldTrump Shut th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>9193</td>\n",
       "      <td>Happy Birthday you stupid fucking bitch. I hop...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8993</th>\n",
       "      <td>9194</td>\n",
       "      <td>So over everything being called a fucking bitc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>9195</td>\n",
       "      <td>Both are dopes, who cares who wins the \"Most H...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>9196</td>\n",
       "      <td>@mmdwriter @JRubinBlogger @BenSasse I am proud...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>9197</td>\n",
       "      <td>@CheriJacobus Hollywood is complicit in the ra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>9198</td>\n",
       "      <td>@amaziah_filani What a fucking cunt I hate see...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>9199</td>\n",
       "      <td>Hysterical woman like @CoryBooker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>9200</td>\n",
       "      <td>Nearly every woman I know has #meToo in their ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  HS  TR  AG\n",
       "0      201  Hurray, saving us $$$ in so many ways @potus @...   1   0   0\n",
       "1      202  Why would young fighting age men be the vast m...   1   0   0\n",
       "2      203  @KamalaHarris Illegals Dump their Kids at the ...   1   0   0\n",
       "3      204  NY Times: 'Nearly All White' States Pose 'an A...   0   0   0\n",
       "4      205  Orban in Brussels: European leaders are ignori...   0   0   0\n",
       "5      206  @KurtSchlichter LEGAL is. Not illegal. #BuildT...   1   0   0\n",
       "6      207  @RitaPanahi @826Maureen @RealCandaceO Antifa a...   0   0   0\n",
       "7      208  Ex-Teacher Pleads Not guilty To Rape Charges h...   0   0   0\n",
       "8      209  still places on our Bengali (Sylheti) class! i...   0   0   0\n",
       "9      210  DFID Africa Regional Profile: July 2018 https:...   0   0   0\n",
       "10     211  Watch: Benjamin Netanyahu backs Trump's decisi...   0   0   0\n",
       "11     212  @RealDonaldTrump @HouseGOP Illegals are dumpin...   1   0   1\n",
       "12     213  While Costa Rica has received the most asylum ...   0   0   0\n",
       "13     214  US immigrant policy to enter US has always bee...   0   0   0\n",
       "14     215  Italy’s populist coalition poised to defy EU w...   0   0   0\n",
       "15     216  Lithuania, Romania aided CIA torture, top Euro...   1   0   1\n",
       "16     217  Worldbank reports that in the next 30 years ma...   1   0   1\n",
       "17     218  Rich African Countries don't take in African M...   1   0   0\n",
       "18     219  New research uncovers successes and failures o...   0   0   0\n",
       "19     220  Immigration why us 2 Million EU Migrants allow...   0   0   0\n",
       "20     221  @NBCNews @MSNBC @jacobsoboroff @DatelineNBC Cl...   0   0   0\n",
       "21     222  Hitler left a stain on Germany for the atrocit...   0   0   0\n",
       "22     223  Over the past two weeks, 1,172 refugees arrive...   0   0   0\n",
       "23     224  Church leaders determine to ease #economic pro...   0   0   0\n",
       "24     225  And why should he now buckle to their demands ...   0   0   0\n",
       "25     226  @WattersWorld @JesseBWatters @BillSpadea How a...   1   0   1\n",
       "26     227  It is a cruel irony that sikhs often **look** ...   0   0   0\n",
       "27     228  EU’s hailed migrant plan ‘˜a road to Hell’ Cze...   1   0   1\n",
       "28     229  Could you open up your home to refugees in nee...   0   0   0\n",
       "29     230  MS-13 spreads to 22 states, fed by 300,000 ill...   1   0   1\n",
       "...    ...                                                ...  ..  ..  ..\n",
       "8970  9171                           nbs stfu hoe ik bout you   1   1   1\n",
       "8971  9172  PSA MMLD HATERS )) unfortunately for you, our ...   0   0   0\n",
       "8972  9173  @artbychristinem @AnnCoulter Perhaps Cory Book...   0   0   0\n",
       "8973  9174  Yes Brooke! Give that bitch the hell she deser...   1   1   1\n",
       "8974  9175  @GOPChairwoman @TWIGGY4065 I know. Booker and ...   1   1   0\n",
       "8975  9176  @howroute @legndofphoenix Lol you sound like t...   0   0   0\n",
       "8976  9177  @DogginTrump The whore bitch spoke! STFU Melan...   1   1   1\n",
       "8977  9178  @AnnCoulter But if the shoe was on the other f...   1   1   0\n",
       "8978  9179  Ladies want a task for your to do list today? ...   1   0   1\n",
       "8979  9180  The voices in your head arent YOU. Theyre your...   0   0   0\n",
       "8980  9181  @onnyssaaa well stfu then BITCH you coming to ...   1   1   1\n",
       "8981  9182  Once a stripper always a skank an a ( Y ) a ho...   1   0   0\n",
       "8982  9183  One of the biggest reason I never wanted to co...   1   0   0\n",
       "8983  9184  All you niggas saying no grown man should be t...   0   0   0\n",
       "8984  9185  @DaddyDaddymac @_QueenofStaves @FLOTUS @FLOTUS...   1   1   1\n",
       "8985  9186  Money can't buy you happiness but it can buy y...   1   1   0\n",
       "8986  9187  Real shit like stfu and eat my pussy since u c...   0   0   0\n",
       "8987  9188  ' teaching women how to wear modest clothes an...   0   0   0\n",
       "8988  9189  @kimguilfoyle Does it bother you that Jrs kids...   1   1   0\n",
       "8989  9190  @AnnCoulter Ann you are the funniest. I think ...   0   0   0\n",
       "8990  9191  @eyehatezod @PopeRichard I refuse to believe t...   0   0   0\n",
       "8991  9192  @CliffShep @MiaFarrow @realDonaldTrump Shut th...   1   1   1\n",
       "8992  9193  Happy Birthday you stupid fucking bitch. I hop...   1   1   1\n",
       "8993  9194  So over everything being called a fucking bitc...   0   0   0\n",
       "8994  9195  Both are dopes, who cares who wins the \"Most H...   1   1   0\n",
       "8995  9196  @mmdwriter @JRubinBlogger @BenSasse I am proud...   0   0   0\n",
       "8996  9197  @CheriJacobus Hollywood is complicit in the ra...   0   0   0\n",
       "8997  9198  @amaziah_filani What a fucking cunt I hate see...   1   1   1\n",
       "8998  9199                  Hysterical woman like @CoryBooker   0   0   0\n",
       "8999  9200  Nearly every woman I know has #meToo in their ...   0   0   0\n",
       "\n",
       "[9000 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lectura import load_data\n",
    "df = load_data('../../data/train_en_B.tsv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9000 tweets in total. We can examinate the distribution of the dataset for binary hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HS\n",
       "0    0.579667\n",
       "1    0.420333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('HS').size() / df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 5217 (58%) no hate speech\n",
    "* 3783 (42%) hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AG\n",
       "0    0.587893\n",
       "1    0.412107\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['HS'] == 1].groupby('AG').size() / 3783"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2224 (59%) no agressive\n",
    "* 1559 (41%) agressive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TR\n",
       "0    0.645519\n",
       "1    0.354481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['HS'] == 1].groupby('TR').size() / 3783"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2442 (65%) no target\n",
    "* 1341 (35%) target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see if there is any null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id      0\n",
       "text    0\n",
       "HS      0\n",
       "TR      0\n",
       "AG      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start seeing general information about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000 entries, 0 to 8999\n",
      "Data columns (total 5 columns):\n",
      "id      9000 non-null int64\n",
      "text    9000 non-null object\n",
      "HS      9000 non-null int64\n",
      "TR      9000 non-null int64\n",
      "AG      9000 non-null int64\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 351.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers must work with numbers type so we see if any label is encoded as object in order to transform object types into int64 types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can list non numerical properties, with a boolean indexing of the Series df.dtypes\n",
    "df.dtypes[df.dtypes == object]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have to make any encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gsitk preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsitk.preprocess import pprocess_twitter, normalize, simple\n",
    "import string\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import emoji\n",
    "class gsitkTransformer(BaseEstimator, TransformerMixin):\n",
    "    emojis_list = emoji.UNICODE_EMOJI\n",
    "    emoji_pattern = emoji.get_emoji_regexp()\n",
    "    trash = ['“', '”', '—', '’', '–', '«', '»', '・・・', 'tq', '€', '…', '‘', 'elonghashtag', 'âž\\x9d', 'ðÿ',\n",
    "             '¦', '‹ðÿ\\x8f', 'â‚¬', '„', '¯', 'ðÿ‡\\xadðÿ‡·', 'âšï¸\\x8f', '‰', 'ðÿ¤', 'ª', '\\x8f', \n",
    "             'ðÿ¥\\x81ðÿ¥\\x81', 'ðÿ˜', '♪', '►', '•', '͡°', 'âž\\x9d', '¤', '〝']\n",
    "    stop = stopwords.words('english')\n",
    "    def tokenize_doc(self, doc):\n",
    "        text = pprocess_twitter.preprocess(doc).replace('<allcaps>', '').replace('<elong>', '')\n",
    "        text = text.replace('\\u2060', '').replace('\\u2066', '').replace('¤', '').replace('ª', '')\n",
    "        text = text.replace('<hastag>', '<hashtag>').replace('\\u2069', '').replace('…', '').replace('˜', '')\n",
    "        text = text.replace('<', '').replace('>', '').replace('¿', '').replace('—', '')\n",
    "        text = text.replace('¡', '').replace('.user', 'user')       \n",
    "        \n",
    "        tokens = normalize.preprocess(text)\n",
    "        tokens = [w for w in tokens if w not in string.punctuation and w not in self.trash \n",
    "                  and w not in self.stop and w not in self.emojis_list\n",
    "                  and not self.emoji_pattern.search(w)]\n",
    "        return tokens\n",
    "    \n",
    "    def fit(self, docs, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, docs):\n",
    "        return [self.tokenize_doc(doc) for doc in docs]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsitk.features.word2vec import Word2VecFeatures\n",
    "w2v_extractor = Word2VecFeatures(w2v_model_path='../../../../NOBACKUP/crawl-300d-2M.vec', w2v_format='google_txt', convolution=[1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simon Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lectura import lexicon_generation\n",
    "lexicon = lexicon_generation(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# lexicon mejorado\n",
    "textrf = gsitkTransformer()\n",
    "\n",
    "#Agressive\n",
    "agressive = df['text'][df['AG'] == 1].values\n",
    "agressive_tokens = textrf.transform(agressive)\n",
    "agressive_tokens = [word for doc in agressive_tokens for word in doc]\n",
    "agressive_lexicon = []\n",
    "\n",
    "contador = Counter(agressive_tokens)\n",
    "comunes = contador.most_common()\n",
    "\n",
    "for tupla in comunes:\n",
    "    agressive_lexicon.append(tupla[0])\n",
    "    \n",
    "# Target\n",
    "target = df['text'][df['TR'] == 1].values\n",
    "target_tokens = textrf.transform(target)\n",
    "target_tokens = [word for doc in target_tokens for word in doc]\n",
    "target_lexicon = []\n",
    "\n",
    "contador = Counter(target_tokens)\n",
    "comunes = contador.most_common()\n",
    "\n",
    "for tupla in comunes:\n",
    "    target_lexicon.append(tupla[0])\n",
    "target_lexicon = list(set(target_lexicon) - set(agressive_lexicon))\n",
    "lexicon_mejorado = [agressive_lexicon, target_lexicon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# lexicon mejorado\n",
    "textrf = gsitkTransformer()\n",
    "\n",
    "# HS\n",
    "hs = df['text'][df['HS'] == 1].values\n",
    "hs_tokens = textrf.transform(hs)\n",
    "hs_tokens = [word for doc in hs_tokens for word in doc]\n",
    "hs_lexicon = []\n",
    "\n",
    "contador = Counter(hs_tokens)\n",
    "comunes = contador.most_common()\n",
    "\n",
    "for tupla in comunes:\n",
    "    hs_lexicon.append(tupla[0])\n",
    "    \n",
    "# NO HS\n",
    "no_hs = df['text'][df['HS'] == 0].values\n",
    "no_hs_tokens = textrf.transform(no_hs)\n",
    "no_hs_tokens = [word for doc in no_hs_tokens for word in doc]\n",
    "no_hs_lexicon = []\n",
    "\n",
    "contador = Counter(no_hs_tokens)\n",
    "comunes = contador.most_common()\n",
    "\n",
    "for tupla in comunes:\n",
    "    no_hs_lexicon.append(tupla[0])\n",
    "no_hs_lexicon = list(set(no_hs_lexicon) - set(hs_lexicon))\n",
    "lexicon_mejorado = [hs_lexicon, no_hs_lexicon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsitk.features import simon\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "embedding_model = KeyedVectors.load_word2vec_format('../../../../NOBACKUP/crawl-300d-2M.vec', binary=False)\n",
    "simon_model = simon.Simon(lexicon=lexicon_mejorado, embedding=embedding_model, n_lexicon_words=100)\n",
    "similarity_model = simon.simon_pipeline(simon_transformer=simon_model, percentile=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "postive_words = opinion_lexicon.positive()\n",
    "negative_words = opinion_lexicon.negative()\n",
    "negative_words = list(set(negative_words) - set(postive_words))\n",
    "sentiment_lexicon = [postive_words, negative_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lectura import read_afinn\n",
    "afinn = read_afinn('../../data/AFINN-111.txt.txt')\n",
    "afinn_lexicon['afinn'] = [list(afinn.index[afinn['value'] > 0].values), list(afinn.index[afinn['value'] < 0].values)]\n",
    "afinn_lexicon_values['afinn'] = afinn['value'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lectura import read_anew\n",
    "anew = read_anew('../../data/all.csv')\n",
    "anew_lexicon['anew'] = [list(anew.Description[anew['value'] > 0].values), list(anew.Description[anew['value'] < 0].values)]\n",
    "anew_lexicon_values['anew'] = anew.set_index('Description')['value'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiwordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiwn = read_swn()\n",
    "swn_lexicon['swn'] = [list(sentiwn.index[sentiwn['value'] > 0].values), list(sentiwn.index[sentiwn['value'] < 0].values)]\n",
    "lswn_exicon_values['swn'] = sentiwn['value'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = simon.Simon(lexicon=sentiment_lexicon, embedding=embedding_model, n_lexicon_words=250)\n",
    "senti_model = simon.simon_pipeline(simon_transformer=sentiment_model, percentile=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_vocabulary = [word for sublexicon in sentiment_lexicon for word in sublexicon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subjectivity Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lectura import subjectivity_lexicon_generation\n",
    "subjectivity_lexicon = subjectivity_lexicon_generation()\n",
    "subjectivity_model = simon.Simon(lexicon=subjectivity_lexicon, embedding=embedding_model, n_lexicon_words=100)\n",
    "subj_model = simon.simon_pipeline(simon_transformer=subjectivity_model, percentile=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjectivity_vocabulary = [word for sublexicon in subjectivity_lexicon for word in sublexicon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hashtag lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lectura import hashtag_lexicon_generation\n",
    "hashtag_lexicon = hashtag_lexicon_generation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lectura import english_tokenizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "ngrams_featurizer = Pipeline([\n",
    "  ('count_vectorizer',  CountVectorizer(ngram_range = (2, 3), encoding = 'ISO-8859-1', \n",
    "                                        tokenizer=english_tokenizer)),\n",
    "  ('tfidf_transformer', TfidfTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimators and hyperparams to be used will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, linear_model, tree, ensemble, naive_bayes, neighbors, gaussian_process, multiclass\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "less_than_1 = [.0001,.001,.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "classifiers = {\n",
    "    'logistic_regression': \n",
    "                   {'model': linear_model.LogisticRegression(), \n",
    "                    'params': \n",
    "                    {'clf__penalty': ['l1','l2'], 'clf__tol': [0.0001,0.001,0.01,0.1], \n",
    "                     'clf__C': np.append(less_than_1, np.arange(1,16))}}, \n",
    "               'linear_SVC': \n",
    "                   {'model': svm.LinearSVC(dual=False), \n",
    "                    'params': \n",
    "                    {'clf__penalty': ['l1','l2'], 'clf__tol': [0.0001,0.001,0.01,0.1], \n",
    "                     'clf__C': np.append(less_than_1, np.arange(1,16))}}, \n",
    "               'random_forest': \n",
    "                   {'model': ensemble.RandomForestClassifier(), \n",
    "                    'params': \n",
    "                    {'clf__n_estimators': np.arange(10, 110, 10), 'clf__max_depth': np.append(np.arange(1, 11), None)}},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the features and the estimators it's time to split the dataset into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test spliting\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test data and exploration in the same way than train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18201</td>\n",
       "      <td>I swear I’m getting to places just in the nick...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18202</td>\n",
       "      <td>I’m an immigrant — and Trump is right on immig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18203</td>\n",
       "      <td>#IllegalImmigrants #IllegalAliens #ElectoralSy...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18204</td>\n",
       "      <td>@DRUDGE_REPORT We have our own invasion issues...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18205</td>\n",
       "      <td>Worker Charged With Sexually Molesting Eight C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18206</td>\n",
       "      <td>UN picks refugees for UK, picks mostly Syrian ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18207</td>\n",
       "      <td>@htTweets Delhi will be much better under Prez...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18208</td>\n",
       "      <td>Global Compact on Migration moves forward http...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18209</td>\n",
       "      <td>Violence toward tourists in Barcelona, Spain -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18210</td>\n",
       "      <td>Immigration decline costing UK economy billion...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18211</td>\n",
       "      <td>@NBCPolitics @MSNBC After 20 days in jail the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18212</td>\n",
       "      <td>@CBPArizona This is insane. 125 last weekend. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18213</td>\n",
       "      <td>Reality Nike, He Did It, unlike you and all yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18214</td>\n",
       "      <td>Libyan coast guard rescues some 160 #Europe-bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18215</td>\n",
       "      <td>We need to encourage President Trump to keep t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18216</td>\n",
       "      <td>Watch: Bangladeshi immigrant thinks he is abov...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18217</td>\n",
       "      <td>Our Immigration Legal Services department is n...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18218</td>\n",
       "      <td>Texas woman, 21, dies after falling from movin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18219</td>\n",
       "      <td>We must reject the \"globalization of indiffere...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18220</td>\n",
       "      <td>#ClimateChange doesn't have to be a partisan i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18221</td>\n",
       "      <td>The UN calls on #TrumpAdministration to stop s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18222</td>\n",
       "      <td>Lessons From the Past: Why Eastern European Na...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18223</td>\n",
       "      <td>#EU grants #Spain extra funding to cope with m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18224</td>\n",
       "      <td>@lilmaggie186 @Jim_Jordan Illegals too? #Build...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18225</td>\n",
       "      <td>France adopts tough new law on asylum, immigra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18226</td>\n",
       "      <td>Tourists go home, refugees welcome': why Barce...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>18227</td>\n",
       "      <td>Europe wants centers in Africa to vet migrants...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18228</td>\n",
       "      <td>Paris suburb aka Muslim no go zone home to 300...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>18229</td>\n",
       "      <td>Lost - but happy ! Merkel co. has not realized...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18230</td>\n",
       "      <td>@mamendoza480 @AnthemRespect @KamalaHarris Ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>19171</td>\n",
       "      <td>@KatiePrice How are they trying to destroy you...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>19172</td>\n",
       "      <td>@FoxNews 65 of which were hysterical women?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>19173</td>\n",
       "      <td>@SteveHofstetter SlutWhoreBitch Cunt Coulter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>19174</td>\n",
       "      <td>@Siobhan_ODwyer @theTiser @DrMel_T If you wann...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>19175</td>\n",
       "      <td>People tryna use #BPD and say promiscuity is a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>19176</td>\n",
       "      <td>@DIRTYDA11283731 dats right bitch ass fag cunt...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>19177</td>\n",
       "      <td>@PrincessBravato this stupid skank can barely ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>19178</td>\n",
       "      <td>remember women are inferior to men even though...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>19179</td>\n",
       "      <td>@SenKamalaHarris Its all about $$$$$$ dollar s...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>19180</td>\n",
       "      <td>Well it seems that Trump tweet has cooled off,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>19181</td>\n",
       "      <td>Me: Love Yours-Wing supremacist: SHUT THE FUCK...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>19182</td>\n",
       "      <td>@NTKNet @RyanAFournier @SenKamalaHarris A hyst...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>19183</td>\n",
       "      <td>@PYS_FlyATL You pussy.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>19184</td>\n",
       "      <td>@RawStory Hey guys... maybe it is okay to wink...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>19185</td>\n",
       "      <td>REGINA GEORGE IS THE NASTIEST SKANK BITCH I HA...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>19186</td>\n",
       "      <td>.@CarterLear is a bitch who wants a Halloween ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>19187</td>\n",
       "      <td>@e_l_l_i_s_x0x Skank bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>19188</td>\n",
       "      <td>Just because a woman decides to drop charges c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>19189</td>\n",
       "      <td>@VABVOX Booker acts like a hysterical woman. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>19190</td>\n",
       "      <td>@realDonaldTrump 1st - You were not elected; y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>19191</td>\n",
       "      <td>@KristinP22 @ChuckGrassley @GodlessNZ Lord hav...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>19192</td>\n",
       "      <td>Amaresh Mishra who gave Rape threats to a woma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>19193</td>\n",
       "      <td>@flvwerchild @autumnrainwish Ya recently here ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>19194</td>\n",
       "      <td>@JRubinBlogger @SenFeinstein I wonder what's i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>19195</td>\n",
       "      <td>@Lauren_Southern You're just a skank and every...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>19196</td>\n",
       "      <td>@SamEnvers you unfollowed me? Fuck you pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>19197</td>\n",
       "      <td>@DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>19198</td>\n",
       "      <td>@2beornotbeing Honey, as a fellow white chick,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>19199</td>\n",
       "      <td>I hate bitches who talk about niggaz with kids...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>19200</td>\n",
       "      <td>@AnnCoulter @DonaldJTrumpJr You won the\" life ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  HS  TR  AG\n",
       "0    18201  I swear I’m getting to places just in the nick...   0   0   0\n",
       "1    18202  I’m an immigrant — and Trump is right on immig...   0   0   0\n",
       "2    18203  #IllegalImmigrants #IllegalAliens #ElectoralSy...   1   0   1\n",
       "3    18204  @DRUDGE_REPORT We have our own invasion issues...   1   0   1\n",
       "4    18205  Worker Charged With Sexually Molesting Eight C...   0   0   0\n",
       "5    18206  UN picks refugees for UK, picks mostly Syrian ...   0   0   0\n",
       "6    18207  @htTweets Delhi will be much better under Prez...   0   0   0\n",
       "7    18208  Global Compact on Migration moves forward http...   0   0   0\n",
       "8    18209  Violence toward tourists in Barcelona, Spain -...   0   0   0\n",
       "9    18210  Immigration decline costing UK economy billion...   0   0   0\n",
       "10   18211  @NBCPolitics @MSNBC After 20 days in jail the ...   1   0   1\n",
       "11   18212  @CBPArizona This is insane. 125 last weekend. ...   1   0   1\n",
       "12   18213  Reality Nike, He Did It, unlike you and all yo...   1   0   0\n",
       "13   18214  Libyan coast guard rescues some 160 #Europe-bo...   0   0   0\n",
       "14   18215  We need to encourage President Trump to keep t...   1   0   0\n",
       "15   18216  Watch: Bangladeshi immigrant thinks he is abov...   1   0   0\n",
       "16   18217  Our Immigration Legal Services department is n...   0   0   0\n",
       "17   18218  Texas woman, 21, dies after falling from movin...   0   0   0\n",
       "18   18219  We must reject the \"globalization of indiffere...   0   0   0\n",
       "19   18220  #ClimateChange doesn't have to be a partisan i...   0   0   0\n",
       "20   18221  The UN calls on #TrumpAdministration to stop s...   0   0   0\n",
       "21   18222  Lessons From the Past: Why Eastern European Na...   0   0   0\n",
       "22   18223  #EU grants #Spain extra funding to cope with m...   0   0   0\n",
       "23   18224  @lilmaggie186 @Jim_Jordan Illegals too? #Build...   1   0   0\n",
       "24   18225  France adopts tough new law on asylum, immigra...   1   0   1\n",
       "25   18226  Tourists go home, refugees welcome': why Barce...   0   0   0\n",
       "26   18227  Europe wants centers in Africa to vet migrants...   0   0   0\n",
       "27   18228  Paris suburb aka Muslim no go zone home to 300...   0   0   0\n",
       "28   18229  Lost - but happy ! Merkel co. has not realized...   1   0   0\n",
       "29   18230  @mamendoza480 @AnthemRespect @KamalaHarris Ref...   0   0   0\n",
       "..     ...                                                ...  ..  ..  ..\n",
       "970  19171  @KatiePrice How are they trying to destroy you...   1   1   1\n",
       "971  19172        @FoxNews 65 of which were hysterical women?   1   0   0\n",
       "972  19173       @SteveHofstetter SlutWhoreBitch Cunt Coulter   0   0   0\n",
       "973  19174  @Siobhan_ODwyer @theTiser @DrMel_T If you wann...   0   0   0\n",
       "974  19175  People tryna use #BPD and say promiscuity is a...   1   1   0\n",
       "975  19176  @DIRTYDA11283731 dats right bitch ass fag cunt...   1   1   1\n",
       "976  19177  @PrincessBravato this stupid skank can barely ...   1   1   0\n",
       "977  19178  remember women are inferior to men even though...   1   0   1\n",
       "978  19179  @SenKamalaHarris Its all about $$$$$$ dollar s...   1   1   0\n",
       "979  19180  Well it seems that Trump tweet has cooled off,...   0   0   0\n",
       "980  19181  Me: Love Yours-Wing supremacist: SHUT THE FUCK...   0   0   0\n",
       "981  19182  @NTKNet @RyanAFournier @SenKamalaHarris A hyst...   1   1   0\n",
       "982  19183                             @PYS_FlyATL You pussy.   0   0   0\n",
       "983  19184  @RawStory Hey guys... maybe it is okay to wink...   0   0   0\n",
       "984  19185  REGINA GEORGE IS THE NASTIEST SKANK BITCH I HA...   1   1   1\n",
       "985  19186  .@CarterLear is a bitch who wants a Halloween ...   1   1   0\n",
       "986  19187                         @e_l_l_i_s_x0x Skank bitch   1   1   0\n",
       "987  19188  Just because a woman decides to drop charges c...   0   0   0\n",
       "988  19189  @VABVOX Booker acts like a hysterical woman. T...   0   0   0\n",
       "989  19190  @realDonaldTrump 1st - You were not elected; y...   0   0   0\n",
       "990  19191  @KristinP22 @ChuckGrassley @GodlessNZ Lord hav...   1   1   0\n",
       "991  19192  Amaresh Mishra who gave Rape threats to a woma...   0   0   0\n",
       "992  19193  @flvwerchild @autumnrainwish Ya recently here ...   0   0   0\n",
       "993  19194  @JRubinBlogger @SenFeinstein I wonder what's i...   1   1   0\n",
       "994  19195  @Lauren_Southern You're just a skank and every...   1   1   0\n",
       "995  19196       @SamEnvers you unfollowed me? Fuck you pussy   0   0   0\n",
       "996  19197  @DanReynolds STFU BITCH! AND YOU GO MAKE SOME ...   1   1   1\n",
       "997  19198  @2beornotbeing Honey, as a fellow white chick,...   0   0   0\n",
       "998  19199  I hate bitches who talk about niggaz with kids...   1   0   1\n",
       "999  19200  @AnnCoulter @DonaldJTrumpJr You won the\" life ...   1   1   0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = load_data('../../data/dev_en_A.tsv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HS\n",
       "0    0.573\n",
       "1    0.427\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby('HS').size() / df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AG\n",
       "0    0.522248\n",
       "1    0.477752\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['HS'] == 1].groupby('AG').size() / 427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TR\n",
       "0    0.487119\n",
       "1    0.512881\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['HS'] == 1].groupby('TR').size() / 427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gsitk problematic tweets\n",
    "df.drop([2149], inplace=True)\n",
    "#df.drop([7122], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df['HS'] == 1]\n",
    "df_test = df_test[df_test['HS'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test splitting\n",
    "X_train = df_train['text'].values\n",
    "y_train = df_train['TR'].values\n",
    "X_test = df_test['text'].values\n",
    "y_test = df_test['TR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2441), (1, 1341)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = load_data('../../data/test_en.tsv')\n",
    "df_evaluation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_competition_train = load_data('../../data/train_es_B.tsv')\n",
    "df_competition_test = load_data('../../data/dev_es_B.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_dev = pd.concat([df_competition_train, df_competition_test])\n",
    "df_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_lexicon = generate_lexicon(df_dev)\n",
    "dev_hashtags = hashtag_lexicon_generation(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_HS = df_dev[df_dev['HS'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from lectura import TextTransformer, LexicalStats, english_tokenizer, PosStats, LowerTransformer, SubjectivityStats\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from lectura import TwitterStats\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif, chi2, RFE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer(reduce_len=True, strip_handles=True)\n",
    "gsitk_tokenizer = gsitkTransformer()\n",
    "\n",
    "textFeatures = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('lexical_stats', Pipeline([\n",
    "            ('stats', LexicalStats()),\n",
    "            ('vectors', DictVectorizer()),\n",
    "            ('scaler', MaxAbsScaler())\n",
    "        ])),\n",
    "        ('pos_stats', Pipeline([\n",
    "            ('pos_stats', PosStats()),\n",
    "            ('vectors', DictVectorizer())\n",
    "        ])),\n",
    "        ('word_embeddings', Pipeline([\n",
    "            ('text_to_tokens', gsitkTransformer()),\n",
    "            ('embedding_features', w2v_extractor),\n",
    "        ])),\n",
    "        ('simon_features', Pipeline([\n",
    "            ('text_to_tokens', gsitkTransformer()),\n",
    "            ('similarity', similarity_model),\n",
    "        ])),\n",
    "        ('sentiments_simon', Pipeline([\n",
    "            ('text_to_tokens', gsitkTransformer()),\n",
    "            ('sentiment', senti_model),\n",
    "        ])),\n",
    "        ('subjectivity_simon', Pipeline([\n",
    "            ('text_to_tokens', gsitkTransformer()),\n",
    "            ('subjectivity_simon', subj_model),\n",
    "        ])),\n",
    "        ('subjectivity', TfidfVectorizer(vocabulary=subjectivity_vocabulary, tokenizer=tweet_tokenizer.tokenize)),\n",
    "        ('words', TfidfVectorizer(tokenizer=english_tokenizer)),\n",
    "        ('ngrams', ngrams_featurizer),\n",
    "        ('character_ngram', TfidfVectorizer(analyzer='char', ngram_range=(2,9))),\n",
    "        ('sentiments', TfidfVectorizer(vocabulary=sentiment_vocabulary, tokenizer=tweet_tokenizer.tokenize)),\n",
    "        ('emojis', TfidfVectorizer(token_pattern=emoji.get_emoji_regexp(), tokenizer=tweet_tokenizer.tokenize)),\n",
    "        ('hashtags', Pipeline([\n",
    "            ('lowercase_transformation', LowerTransformer()),\n",
    "            ('hashtag_vectorizer', TfidfVectorizer(vocabulary=hashtag_lexicon, tokenizer=tweet_tokenizer.tokenize))            \n",
    "        ])), \n",
    "        ('twitter stats', Pipeline([\n",
    "            ('stats', TwitterStats()),\n",
    "            ('vectors', DictVectorizer()),\n",
    "            ('scaler', MaxAbsScaler())\n",
    "        ])),\n",
    "        ('subjectivity_stats', Pipeline([\n",
    "            ('stats', SubjectivityStats()),\n",
    "            ('subjectivity_vectors', DictVectorizer())\n",
    "        ])),\n",
    "        ('lda', Pipeline([\n",
    "            ('count', CountVectorizer(tokenizer=english_tokenizer)),\n",
    "            ('lda', LatentDirichletAllocation(n_topics=10, max_iter=5, learning_method='online', learning_offset=50,\n",
    "                                             random_state=0))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('KBest', SelectKBest(f_classif, k=2500)),\n",
    "    #('Percentile', SelectPercentile(f_classif, percentile=0.75))\n",
    "    #('PCA', PCA(n_components=0.90, svd_solver='full'))\n",
    "    #('RFE', RFE(estimator, n_features_to_select=10000, step=100))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"More of Australia's rejected migrants headed to your American city https://t.co/dV3WozlXTX via @wordpressdotcom What's up with this ? Is USA the dumping ground ?\""
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[866]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, vstack, coo_matrix\n",
    "\n",
    "features_train = textFeatures.fit_transform(X_train, y_train)\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = textFeatures.transform(X_test)\n",
    "features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ag = df_HS['text'].values\n",
    "y_ag = df_HS['AG'].values\n",
    "X_tr = df_HS['text'].values\n",
    "y_tr = df_HS['TR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(Counter(y_ag).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dev = textFeatures.fit_transform(X_ag, y_ag)\n",
    "features_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "% pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3116, 10000)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "features_train, y_train = rus.fit_resample(features_train, y_train)\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1558), (1, 1558)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "n_jobs = int(multiprocessing.cpu_count() * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from evaluation import evaluate\n",
    "results = evaluate(features_train, y_train, features_test, y_test, classifiers, n_jobs=n_jobs)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import createModel\n",
    "# Agressive classifier: k=32500 and non-negative features 0.72\n",
    "# classifier = svm.LinearSVC(dual=False, penalty='l1', tol=0.01, C=0.5)\n",
    "\n",
    "# Target Classifier\n",
    "# classifier = ...\n",
    "\n",
    "model = createModel(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(features_dev, y_ag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = load_data('en_a.tsv')\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for row in tqdm(df_results.itertuples()):\n",
    "        df_results.at[row.Index, 'AG'] = 0 if row[3] == 0 else model.predict(textFeatures.transform([row[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_test.copy()\n",
    "df_results.drop(columns=['text', 'HS', 'TR', 'AG'], inplace=True)\n",
    "df_results.insert(1, 'prediction', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.drop(columns=['text'], inplace=True)\n",
    "df_results.to_csv('es_b.tsv', index=False, sep=\"\\t\", header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
